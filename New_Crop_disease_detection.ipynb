{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpjiL6/d302cep0CEgOoO/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndegwaanth/Crop-disease_prdiction/blob/main/New_Crop_disease_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpNNbWJfXDR7",
        "outputId": "ea79ef65-11cd-4092-dcbc-d40f7daaee2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.11/dist-packages (4.3.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagehash) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagehash) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imagehash) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import imagehash\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import hashlib\n",
        "from PIL import Image, UnidentifiedImageError"
      ],
      "metadata": {
        "id": "jQa5TnUGXaJN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_folder_and_extension(input_folder, output_folder):\n",
        "  \"\"\"\n",
        "  check the existence of the folder being uploaded and the the extension\n",
        "  of the dataset that are present\n",
        "  \"\"\"\n",
        "  if not os.listdir(input_folder):\n",
        "    os.makedir(output_folder)\n",
        "\n",
        "\n",
        "  for filename in os.listdir(input_folder):\n",
        "    if filename.endswith('.jpg') or filename.endswith(\".png\"):\n",
        "      pass"
      ],
      "metadata": {
        "id": "YBuzOZSZhAAm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Resizing Images\n",
        "Resize all images to a consistent resolution (e.g., 224x224 or 256x256) to ensure uniformity in input size for the CNN."
      ],
      "metadata": {
        "id": "7a9Eozd6kUrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_images(input_folder, output_folder, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Resizes all images in the input directory to the target size using OpenCV.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Path to the directory containing input images.\n",
        "        output_dir (str): Path to the directory to save resized images.\n",
        "        target_size (tuple): Target size (width, height) for resizing. Default is (224, 224).\n",
        "    \"\"\"\n",
        "    if not os.listdir(input_folder):\n",
        "      os.makedir(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "      if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Resize the image\n",
        "        resize_image = cv2.resize(image, target_size)\n",
        "\n",
        "        # saving the resize image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, resize_image)\n",
        "\n",
        "    print(f\"Resizing complete! Resized images saved in {output_folder}\")\n"
      ],
      "metadata": {
        "id": "9-76Y7c4dz7b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Normalization\n",
        "Normalize pixel values to a range of [0, 1] or [-1, 1] by dividing by 255 or using mean and standard deviation normalization."
      ],
      "metadata": {
        "id": "Kk3zPrL0kj5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_images_opencv(input_dir, output_dir, normalize_range=\"0_1\"):\n",
        "    \"\"\"\n",
        "    Normalizes all images in the input directory using OpenCV.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Path to the directory containing resized images.\n",
        "        output_dir (str): Path to the directory to save normalized images.\n",
        "        normalize_range (str): Normalization range. Options: \"0_1\" (default) or \"-1_1\".\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Loop through all images in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check for image files\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Normalize the image\n",
        "            if normalize_range == \"0_1\":\n",
        "                normalized_image = image / 255.0  # Normalize to [0, 1]\n",
        "            elif normalize_range == \"-1_1\":\n",
        "                normalized_image = (image / 127.5) - 1  # Normalize to [-1, 1]\n",
        "            else:\n",
        "                raise ValueError(\"Invalid normalize_range. Use '0_1' or '-1_1'.\")\n",
        "\n",
        "            # Convert back to uint8 for saving (optional, only if you want to visualize normalized images)\n",
        "            normalized_image_uint8 = (normalized_image * 255).astype(np.uint8)\n",
        "\n",
        "            # Save the normalized image\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, normalized_image_uint8)\n",
        "\n",
        "    print(f\"Normalization complete! Normalized images saved in {output_dir}\")"
      ],
      "metadata": {
        "id": "0nUQrRtCeU1K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Grayscale Conversion\n",
        "Convert RGB images to grayscale if color information is not critical for disease detection"
      ],
      "metadata": {
        "id": "LVLo4SUTlExb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_grayscale_opencv(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Converts all RGB images in the input directory to grayscale using OpenCV.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Path to the directory containing input images.\n",
        "        output_dir (str): Path to the directory to save grayscale images.\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Loop through all images in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check for image files\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Convert the image to grayscale\n",
        "            grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Save the grayscale image\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, grayscale_image)\n",
        "\n",
        "    print(f\"Grayscale conversion complete! Grayscale images saved in {output_dir}\")"
      ],
      "metadata": {
        "id": "TgqCANELk6-O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Color Space Transformation\n",
        "Convert images to alternative color spaces like HSV, LAB, or YCrCb to enhance specific features like disease spots or discoloration."
      ],
      "metadata": {
        "id": "JuICFv_llVZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_color_space_opencv(input_dir, output_dir, color_space=\"HSV\"):\n",
        "    \"\"\"\n",
        "    Converts all images in the input directory to the specified color space using OpenCV.\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Path to the directory containing input images.\n",
        "        output_dir (str): Path to the directory to save converted images.\n",
        "        color_space (str): Target color space. Options: \"HSV\", \"LAB\", or \"YCrCb\". Default is \"HSV\".\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Define the color space conversion flag\n",
        "    if color_space == \"HSV\":\n",
        "        conversion_flag = cv2.COLOR_BGR2HSV\n",
        "    elif color_space == \"LAB\":\n",
        "        conversion_flag = cv2.COLOR_BGR2LAB\n",
        "    elif color_space == \"YCrCb\":\n",
        "        conversion_flag = cv2.COLOR_BGR2YCrCb\n",
        "    else:\n",
        "        raise ValueError(\"Invalid color space. Use 'HSV', 'LAB', or 'YCrCb'.\")\n",
        "\n",
        "    # Loop through all images in the input directory\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # Check for image files\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_dir, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Convert the image to the specified color space\n",
        "            converted_image = cv2.cvtColor(image, conversion_flag)\n",
        "\n",
        "            # Save the converted image\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            cv2.imwrite(output_path, converted_image)\n",
        "\n",
        "    print(f\"Color space conversion complete! Converted images saved in {output_dir}\")"
      ],
      "metadata": {
        "id": "YGxj2-bpk_k-"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}